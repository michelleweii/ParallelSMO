# ParallelSMO

*本篇论文已发表在HPCC-2018上，针对SMO算法进行了改进，提出了并行的思路和实现（IPSMO-1 AND IPSMO-2）。*

## SMO
序列最小最优化算法(SMO)可以高效的求解SVM对偶问题，它把原始求解N个参数二次规划问题分解成很多个子二次规划问题分别求解，每个子问题只需要求解2个参数，方法类似于坐标上升，节省时间成本和降低了内存需求。每次启发式选择两个变量进行优化，不断循环，直到达到函数最优值。
《统计学习方法》
SMO的基本思路：如果所有变量的解都满足此优化问题的KKT条件，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。否则，选择两个变量，固定其他变量，针对这两个变量构造一个二次规划问题，这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小。子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定。如此，SMO算法将原问题不断分解为子问题，并对子问题求解，进而达到求解原问题的目的。

\alpha

x_i

## IPSMO-1

## IPSMO-2


# 一级标题
## 二级标题
##### 五级标题
- 列表第一项
- 列表第二项
1. 有序列表第一项
2. 有序列表第二项
[标题](链接地址)
![图片描述](图片链接地址)
*斜体*
**粗体**
> 引用段落
```
代码块
```
